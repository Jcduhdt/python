{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 直接复制大佬的代码了\n",
    "# -*- coding:UTF-8 -*-\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess as sp\n",
    "from lxml import etree\n",
    "import requests\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用代理: {'https': '222.182.121.10:8118'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "函数说明:获取IP代理\n",
    "Parameters:\n",
    "    page - 高匿代理页数,默认获取第一页\n",
    "Returns:\n",
    "    proxys_list - 代理列表\n",
    "Modify:\n",
    "    2017-05-27\n",
    "\"\"\"\n",
    "def get_proxys(page = 1):\n",
    "    #requests的Session可以自动保持cookie,不需要自己维护cookie内容\n",
    "    S = requests.Session()\n",
    "    #西刺代理高匿IP地址\n",
    "    target_url = 'http://www.xicidaili.com/nn/%d' % page\n",
    "    #完善的headers\n",
    "    target_headers = {'Upgrade-Insecure-Requests':'1',\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
    "        'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Referer':'http://www.xicidaili.com/nn/',\n",
    "        'Accept-Encoding':'gzip, deflate, sdch',\n",
    "        'Accept-Language':'zh-CN,zh;q=0.8',\n",
    "    }\n",
    "    #get请求\n",
    "    target_response = S.get(url = target_url, headers = target_headers)\n",
    "    #utf-8编码\n",
    "    target_response.encoding = 'utf-8'\n",
    "    #获取网页信息\n",
    "    target_html = target_response.text\n",
    "    #获取id为ip_list的table\n",
    "    bf1_ip_list = BeautifulSoup(target_html, 'lxml')\n",
    "    bf2_ip_list = BeautifulSoup(str(bf1_ip_list.find_all(id = 'ip_list')), 'lxml')\n",
    "    ip_list_info = bf2_ip_list.table.contents\n",
    "    #存储代理的列表\n",
    "    proxys_list = []\n",
    "    #爬取每个代理信息\n",
    "    for index in range(len(ip_list_info)):\n",
    "        if index % 2 == 1 and index != 1:\n",
    "            dom = etree.HTML(str(ip_list_info[index]))\n",
    "            ip = dom.xpath('//td[2]')\n",
    "            port = dom.xpath('//td[3]')\n",
    "            protocol = dom.xpath('//td[6]')\n",
    "            proxys_list.append(protocol[0].text.lower() + '#' + ip[0].text + '#' + port[0].text)\n",
    "    #返回代理列表\n",
    "    return proxys_list\n",
    "\n",
    "\"\"\"\n",
    "函数说明:检查代理IP的连通性\n",
    "Parameters:\n",
    "    ip - 代理的ip地址\n",
    "    lose_time - 匹配丢包数\n",
    "    waste_time - 匹配平均时间\n",
    "Returns:\n",
    "    average_time - 代理ip平均耗时\n",
    "Modify:\n",
    "    2017-05-27\n",
    "\"\"\"\n",
    "def check_ip(ip, lose_time, waste_time):\n",
    "    #命令 -n 要发送的回显请求数 -w 等待每次回复的超时时间(毫秒)\n",
    "    cmd = \"ping -n 3 -w 3 %s\"\n",
    "    #执行命令\n",
    "    p = sp.Popen(cmd % ip, stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "    #获得返回结果并解码\n",
    "    out = p.stdout.read().decode(\"gbk\")\n",
    "    #丢包数\n",
    "    lose_time = lose_time.findall(out)\n",
    "    #当匹配到丢失包信息失败,默认为三次请求全部丢包,丢包数lose赋值为3\n",
    "    if len(lose_time) == 0:\n",
    "        lose = 3\n",
    "    else:\n",
    "        lose = int(lose_time[0])\n",
    "    #如果丢包数目大于2个,则认为连接超时,返回平均耗时1000ms\n",
    "    if lose > 2:\n",
    "        #返回False\n",
    "        return 1000\n",
    "    #如果丢包数目小于等于2个,获取平均耗时的时间\n",
    "    else:\n",
    "        #平均时间\n",
    "        average = waste_time.findall(out)\n",
    "        #当匹配耗时时间信息失败,默认三次请求严重超时,返回平均好使1000ms\n",
    "        if len(average) == 0:\n",
    "            return 1000\n",
    "        else:\n",
    "            #\n",
    "            average_time = int(average[0])\n",
    "            #返回平均耗时\n",
    "            return average_time\n",
    "\n",
    "\"\"\"\n",
    "函数说明:初始化正则表达式\n",
    "Parameters:\n",
    "    无\n",
    "Returns:\n",
    "    lose_time - 匹配丢包数\n",
    "    waste_time - 匹配平均时间\n",
    "Modify:\n",
    "    2017-05-27\n",
    "\"\"\"\n",
    "def initpattern():\n",
    "    #匹配丢包数\n",
    "    lose_time = re.compile(u\"丢失 = (\\d+)\", re.IGNORECASE)\n",
    "    #匹配平均时间\n",
    "    waste_time = re.compile(u\"平均 = (\\d+)ms\", re.IGNORECASE)\n",
    "    return lose_time, waste_time\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #初始化正则表达式\n",
    "    lose_time, waste_time = initpattern()\n",
    "    #获取IP代理\n",
    "    proxys_list = get_proxys(1)\n",
    "\n",
    "    #如果平均时间超过200ms重新选取ip\n",
    "    while True:\n",
    "        #从100个IP中随机选取一个IP作为代理进行访问\n",
    "        proxy = random.choice(proxys_list)\n",
    "        split_proxy = proxy.split('#')\n",
    "        #获取IP\n",
    "        ip = split_proxy[1]\n",
    "        #检查ip\n",
    "        average_time = check_ip(ip, lose_time, waste_time)\n",
    "        if average_time > 200:\n",
    "            #去掉不能使用的IP\n",
    "            proxys_list.remove(proxy)\n",
    "            print(\"ip连接超时, 重新获取中!\")\n",
    "        if average_time < 200:\n",
    "            break\n",
    "\n",
    "    #去掉已经使用的IP\n",
    "    proxys_list.remove(proxy)\n",
    "    proxy_dict = {split_proxy[0]:split_proxy[1] + ':' + split_proxy[2]}\n",
    "    print(\"使用代理:\", proxy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
