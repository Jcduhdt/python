{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#嘿嘿 下载bing的每日一图\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "from urllib import error\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    list_urls = []\n",
    "    for nums in range(1,15):\n",
    "        url = 'https://bing.ioliu.cn/?p=%s' % nums\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36 Edge/17.17134'\n",
    "        }\n",
    "        req = requests.get(url = url,headers = headers)\n",
    "        req.encoding = 'utf-8'\n",
    "        html = req.text\n",
    "        soup = BeautifulSoup(html,'html.parser')\n",
    "        target_urls = soup.find_all('div',class_ = 'card progressive')\n",
    "        for each in target_urls:\n",
    "            #这里发生错误，导致我在这里卡了半天，因为后续的命名问题其实直接可以就放url就行了\n",
    "            #不用each.div.h3.string\n",
    "            #有些网站命名有很多\\n和空格 使用replace去除\\n使用strip()去除空格\n",
    "            #是哦那个remove的时候提示没有这种操作，我也没有研究\n",
    "            #each.div.a.text.replace('\\n','').strip()\n",
    "            list_urls.append(each.div.h3.string + '=' + each.img.get('src'))\n",
    "    print('链接收集完毕')\n",
    "    \n",
    "    if 'bing_images' not in os.listdir():\n",
    "        os.makedirs('bing_images')\n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    for each_img in list_urls:\n",
    "        img_info = each_img.split('=')\n",
    "        img_name = img_info[0]\n",
    "        img_url = img_info[1]\n",
    "        #这个命名用数字来命名，因为bing的命名太长了，中英文很多\n",
    "        #导致下载图片时会报错\n",
    "        #其实用数字命名也挺好的，因为有些网站它的很多图片吗命名重复\n",
    "        #这样会导致下载的图片被覆盖\n",
    "        filename = str(i) + '.jpg'\n",
    "        print('下载：' + filename)\n",
    "        #使用异常捕获挺好的，可以使程序运行下去\n",
    "        #有的网站的链接被禁止了，url失效\n",
    "        # 为什么有时候爬的到，但是有时候都是403\n",
    "        try:\n",
    "            urlretrieve(url = img_url,filename = 'bing_images/' + filename)\n",
    "        except error.URLError as e:\n",
    "            print(e.reason)\n",
    "        #urlretrieve(url = img_url,filename = 'bing_images/' + filename)\n",
    "        time.sleep(1)\n",
    "        i += 1\n",
    "    print('下载完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
